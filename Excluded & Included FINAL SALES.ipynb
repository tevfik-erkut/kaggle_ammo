{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"FINAL_SALES_FILE_DATATHON-Copy1.csv\")\ndf.drop([\"Unnamed: 0\"], 1, inplace = True)\ndf.drop_duplicates(\"SALESFILE_ID\", inplace= True)\ndf.SF_CREATE_DATE = pd.to_datetime(\"2021/06/01\") - pd.to_datetime(df.SF_CREATE_DATE)\ndf.SF_CREATE_DATE = df.SF_CREATE_DATE.dt.days\ndf = df.sort_values(\"SF_CREATE_DATE\", ascending = False)\ndf.loc[df.SALESFILE_ID.isnull(), \"SALESFILE_ID\"] = 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_customer = pd.read_csv(\"FINAL_CUSTOMER_DATATHON-Copy1.csv\")\nfinal_customer.drop([\"Unnamed: 0\"] ,1, inplace = True)\ndf = pd.merge(final_customer, df, on = \"CUSTOMER_ID\", how = \"outer\")\ndel final_customer\ndf.drop_duplicates(inplace =True)\ndf.loc[df.GENDER_ID == 0, \"GENDER_ID\"] = 100\ndf.drop([\"GENDER\"], 1, inplace = True)\ndf.drop([\"CUSTOMER_ID\"], 1, inplace = True)\ndf.drop_duplicates(inplace = True)\nimport numpy as np\nf = lambda x: x.median() if np.issubdtype(x.dtype, np.number) else next(iter(x.mode()), np.nan)\ndf.MARITAL_STATUS.fillna(df.groupby('BASE_CUSTOMER_ID')[\"MARITAL_STATUS\"].transform(f), inplace = True)\ndf.drop([\"MARITAL_STATUS_ID\"], 1, inplace = True)\ndf.BIRTH_DATE.fillna(df.groupby('BASE_CUSTOMER_ID')[\"BIRTH_DATE\"].transform(f), inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime   # 0 indicates 2021/05/31 which is fine\ndef serial_date_to_string(srl_no):\n    new_date = datetime.datetime(2021,6,1,0,0) - datetime.timedelta(srl_no )\n    return new_date.strftime(\"%Y-%m-%d\")\ndf.SF_CREATE_DATE.fillna(-30, inplace = True)\ndf.SF_CREATE_DATE = df.SF_CREATE_DATE.transform(serial_date_to_string)\n\ndf[\"Age\"] = pd.to_datetime(df[\"SF_CREATE_DATE\"]).dt.year - df[\"BIRTH_DATE\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.SF_CREATE_DATE = pd.to_datetime(\"2021/06/01\") - pd.to_datetime(df.SF_CREATE_DATE)\ndf.SF_CREATE_DATE = df.SF_CREATE_DATE.dt.days\ndf.drop([\"BIRTH_DATE\"], 1, inplace = True)\n\ndf.loc[df.Age>85, \"Age\"] = np.nan\ndf.loc[df.Age< 15, \"Age\"] = np.nan\ndf.loc[(df.OCCUPATION == \"Emekli\") & (df.Age <40),\"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\" \ndf.loc[(df.OCCUPATION == \"Öğrenci\") & (df.Age > 24), \"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\" \ndf.loc[(df.OCCUPATION != \"Öğrenci\") & (df.Age <20),\"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\"\ndf.loc[(df.OCCUPATION != \"Emekli\") & (df.Age >64),\"OCCUPATION\"] = \"Emekli\"\n\ndf[\"occupation_fill\"] = df.groupby(\"BASE_CUSTOMER_ID\", sort=False)['OCCUPATION'].apply(lambda x: x.bfill().ffill())\ndf.drop([\"OCCUPATION\"], 1, inplace = True)\ndf.rename(columns = {\"occupation_fill\": \"OCCUPATION\"}, inplace = True)\ndf.Age.fillna(df.groupby(\"OCCUPATION\")[\"Age\"].mean(), inplace = True)\ndf.loc[df.MARITAL_STATUS.isnull(), \"MARITAL_STATUS\"] = \"Diğer\"\ndf.loc[(df.MARITAL_STATUS == \"Bekar\") & (df.Age.isnull()), \"Age\"] = df.loc[df.MARITAL_STATUS == \"Bekar\",\"Age\"].mean()\ndf.loc[(df.MARITAL_STATUS == \"Diğer\") & (df.Age.isnull()), \"Age\"] = df.loc[df.MARITAL_STATUS == \"Diğer\",\"Age\"].mean()\ndf.loc[(df.MARITAL_STATUS == \"Evli\") & (df.Age.isnull()), \"Age\"] = df.loc[df.MARITAL_STATUS == \"Evli\",\"Age\"].mean()\n\ndf.loc[(df.OCCUPATION == \"Emekli\") & (df.Age <40),\"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\" \ndf.loc[(df.OCCUPATION == \"Öğrenci\") & (df.Age > 24), \"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\" \ndf.loc[(df.OCCUPATION != \"Öğrenci\") & (df.Age <20),\"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\"\ndf.loc[(df.OCCUPATION != \"Emekli\") & (df.Age >64),\"OCCUPATION\"] = \"Emekli\"\n\ndf[\"address_fill\"] = df.groupby(\"BASE_CUSTOMER_ID\",\n                                sort=False)['FK_ADDRESS_COMMUNICATION_CITY'].apply(lambda x: x.bfill().ffill())\ns = df.address_fill.value_counts(normalize=True)\nmissing = df['address_fill'].isnull()\ndf.loc[missing,'address_fill'] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\ndf.drop([\"FK_ADDRESS_COMMUNICATION_CITY\"], 1, inplace =True)\ndf.drop_duplicates(inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.REQ_BRAND_CODE.fillna(df.groupby('BASE_CUSTOMER_ID')[\"REQ_BRAND_CODE\"].transform(f), inplace = True)\ndf.REQ_TOPMODEL_CODE.fillna(df.groupby('BASE_CUSTOMER_ID')[\"REQ_TOPMODEL_CODE\"].transform(f), inplace = True)\n\ndf.to_csv(\"TEST_ORAN_FINAL_SALES.csv\", index =False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"INCLUDED PART","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"FINAL_SALES_FILE_DATATHON-Copy1.csv\")\ndf.drop([\"Unnamed: 0\"], 1, inplace = True)\ndf.drop_duplicates(\"SALESFILE_ID\", inplace= True)\ndf.SF_CREATE_DATE = pd.to_datetime(\"2021/06/01\") - pd.to_datetime(df.SF_CREATE_DATE)\ndf.SF_CREATE_DATE = df.SF_CREATE_DATE.dt.days\ndf.SF_CREATE_DATE = df.SF_CREATE_DATE - 92\ndf.loc[df.SALESFILE_ID > 0, \"SALESFILE_ID\"] = 1\ndf.loc[df.SF_CREATE_DATE < 0, \"SALESFILE_ID\"] = 2\ndf = df.sort_values(\"SALESFILE_ID\")\ndf.loc[df.SALESFILE_ID.isnull(), \"SALESFILE_ID\"] = 0\n\nfinal_customer = pd.read_csv(\"FINAL_CUSTOMER_DATATHON-Copy1.csv\")\nfinal_customer.drop([\"Unnamed: 0\"] ,1, inplace = True)\ndf = pd.merge(final_customer, df, on = \"CUSTOMER_ID\", how = \"outer\")\ndel final_customer\ndf.drop_duplicates(inplace =True)\ndf.loc[df.SALESFILE_ID.isnull(), \"SALESFILE_ID\"] = 0\n\ndf.loc[df.GENDER_ID == 0, \"GENDER_ID\"] = 100\ndf.drop([\"GENDER\"], 1, inplace = True)\ndf.drop([\"CUSTOMER_ID\"], 1, inplace = True)\ndf.drop_duplicates(inplace = True)\nimport numpy as np\nf = lambda x: x.median() if np.issubdtype(x.dtype, np.number) else next(iter(x.mode()), np.nan)\ndf.MARITAL_STATUS.fillna(df.groupby('BASE_CUSTOMER_ID')[\"MARITAL_STATUS\"].transform(f), inplace = True)\ndf.drop([\"MARITAL_STATUS_ID\"], 1, inplace = True)\ndf.BIRTH_DATE.fillna(df.groupby('BASE_CUSTOMER_ID')[\"BIRTH_DATE\"].transform(f), inplace = True)\ndf.SF_CREATE_DATE.fillna(0, inplace = True)\ndf.SF_CREATE_DATE = df.SF_CREATE_DATE.transform(serial_date_to_string)\n\ndf[\"Age\"] = pd.to_datetime(df[\"SF_CREATE_DATE\"]).dt.year - df[\"BIRTH_DATE\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.SF_CREATE_DATE = pd.to_datetime(\"2021/03/01\") - pd.to_datetime(df.SF_CREATE_DATE)\ndf.SF_CREATE_DATE = df.SF_CREATE_DATE.dt.days\ndf.drop([\"BIRTH_DATE\"], 1, inplace = True)\n\ndf.loc[df.Age>85, \"Age\"] = np.nan\ndf.loc[df.Age< 15, \"Age\"] = np.nan\ndf.loc[(df.OCCUPATION == \"Emekli\") & (df.Age <40),\"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\" \ndf.loc[(df.OCCUPATION == \"Öğrenci\") & (df.Age > 24), \"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\" \ndf.loc[(df.OCCUPATION != \"Öğrenci\") & (df.Age <20),\"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\"\ndf.loc[(df.OCCUPATION != \"Emekli\") & (df.Age >64),\"OCCUPATION\"] = \"Emekli\"\n\ndf[\"occupation_fill\"] = df.groupby(\"BASE_CUSTOMER_ID\", sort=False)['OCCUPATION'].apply(lambda x: x.bfill().ffill())\ndf.drop([\"OCCUPATION\"], 1, inplace = True)\ndf.rename(columns = {\"occupation_fill\": \"OCCUPATION\"}, inplace = True)\ndf.Age.fillna(df.groupby(\"OCCUPATION\")[\"Age\"].mean(), inplace = True)\ndf.loc[df.MARITAL_STATUS.isnull(), \"MARITAL_STATUS\"] = \"Diğer\"\ndf.loc[(df.MARITAL_STATUS == \"Bekar\") & (df.Age.isnull()), \"Age\"] = df.loc[df.MARITAL_STATUS == \"Bekar\",\"Age\"].mean()\ndf.loc[(df.MARITAL_STATUS == \"Diğer\") & (df.Age.isnull()), \"Age\"] = df.loc[df.MARITAL_STATUS == \"Diğer\",\"Age\"].mean()\ndf.loc[(df.MARITAL_STATUS == \"Evli\") & (df.Age.isnull()), \"Age\"] = df.loc[df.MARITAL_STATUS == \"Evli\",\"Age\"].mean()\n\ndf.loc[(df.OCCUPATION == \"Emekli\") & (df.Age <40),\"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\" \ndf.loc[(df.OCCUPATION == \"Öğrenci\") & (df.Age > 24), \"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\" \ndf.loc[(df.OCCUPATION != \"Öğrenci\") & (df.Age <20),\"OCCUPATION\"] = \"Çalışmıyor/Bilinmiyor\"\ndf.loc[(df.OCCUPATION != \"Emekli\") & (df.Age >64),\"OCCUPATION\"] = \"Emekli\"\n\ndf[\"address_fill\"] = df.groupby(\"BASE_CUSTOMER_ID\",\n                                sort=False)['FK_ADDRESS_COMMUNICATION_CITY'].apply(lambda x: x.bfill().ffill())\ns = df.address_fill.value_counts(normalize=True)\nmissing = df['address_fill'].isnull()\ndf.loc[missing,'address_fill'] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\ndf.drop([\"FK_ADDRESS_COMMUNICATION_CITY\"], 1, inplace =True)\ndf.drop_duplicates(inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.REQ_BRAND_CODE.fillna(df.groupby('BASE_CUSTOMER_ID')[\"REQ_BRAND_CODE\"].transform(f), inplace = True)\ndf.REQ_TOPMODEL_CODE.fillna(df.groupby('BASE_CUSTOMER_ID')[\"REQ_TOPMODEL_CODE\"].transform(f), inplace = True)\ndf.to_csv(\"TRAIN_ORAN_final_sales.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]}]}